{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf6d777-16ec-4e53-96e2-975507f37de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gcsfs\n",
    "import xarray as xr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b3771-7564-4763-b13a-85ecc8cd5d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Google Cloud: this file has locations of all CMIP6 data in the Pangeo Google Cloud Collection\n",
    "fs = gcsfs.GCSFileSystem(token='anon', access='read_only')\n",
    "\n",
    "df = pd.read_csv(\"https://cmip6.storage.googleapis.com/pangeo-cmip6-noQC.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b702958-729a-4ccb-8163-ad8e01257773",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df),'datasets, with columns:\\n',list(df.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.activity_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a useful function for finding the datasets of interest\n",
    "\n",
    "def search_df(df, verbose= False, **search):\n",
    "    \"search by keywords - if list, then match exactly, otherwise match as substring\"\n",
    "    keys = ['activity_id','institution_id','source_id','experiment_id','member_id', 'table_id', 'variable_id', 'grid_label']\n",
    "    d = df\n",
    "    for skey in search.keys():\n",
    "        if isinstance(search[skey], str):  # match a string as a substring\n",
    "            d = d[d[skey].str.contains(search[skey])]\n",
    "        else:\n",
    "            dk = []\n",
    "            for key in search[skey]:       # match a list of strings exactly\n",
    "                dk += [d[d[skey]==key]]\n",
    "            d = pd.concat(dk)\n",
    "            keys.remove(skey)\n",
    "    if verbose:\n",
    "        for key in keys:\n",
    "            print(key,' = ',list(d[key].unique()))      \n",
    "    return d.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e037372b-947e-44a0-a15c-b562cd8b50f5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "asearch = {}\n",
    "asearch['experiment_id'] = ['ssp585']\n",
    "asearch['table_id'] = ['Amon']\n",
    "asearch['variable_id'] = ['tasmin', 'tasmax']\n",
    "# add more as needed\n",
    "\n",
    "#asearch['grid_label'] = ['gn']\n",
    "\n",
    "# Find all datasets matching this search:\n",
    "df_subset = search_df(df,**asearch)\n",
    "\n",
    "# Print first 5 entries\n",
    "df_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(df_subset)} datasets in {df_subset.source_id.nunique()} models matching this search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and save all datasets in netcdf format\n",
    "#\n",
    "# change path to where you want to keep these files\n",
    "path = './'\n",
    "\n",
    "for index,row in df_subset.iterrows():\n",
    "    zstore = row['zstore']\n",
    "    print(f'\\navailable dataset: {zstore}')\n",
    "    varname = row['variable_id']\n",
    "    fullname = zstore.split('gs://cmip6/CMIP6/')[-1].split(f'/{varname}')[0]\n",
    "    shortname = path + varname + '_' + '_'.join(fullname.split('/')[2:])\n",
    "    \n",
    "    ncfile = f'{shortname}.nc'\n",
    "    if os.path.exists(ncfile):\n",
    "        print(f'{ncfile} already exists')\n",
    "        continue\n",
    "        \n",
    "    print(f'saving {ncfile}')\n",
    "    mapper = fs.get_mapper(zstore)\n",
    "    ds = xr.open_zarr(mapper, consolidated=True)   \n",
    "    ds.to_netcdf(ncfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad4558e-ea9c-4b31-8a18-8a44b1587657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeo-Oct2021",
   "language": "python",
   "name": "pangeo-oct2021"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
